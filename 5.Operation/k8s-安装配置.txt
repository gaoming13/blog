# k8s

### 依赖项
- 内存 > 2GB
- 2核CPU以上
- 禁用Swap

### k8s-master

#### 1.安装依赖项

```shell
# 安装vim
yum install vim -y

# 安装traceroute、ifconfig、netstat、route等常用指令
yum install -y tranceroute
yum install -y net-tools


# 查看本机ip
ip addr

# 设置公钥登录
cat ~/.ssh/authorized_keys

# 设置主机名
hostnamectl --static set-hostname k8s-master

# 临时关闭系统的swap
swapoff -a

# 永久关闭系统的swap
vim /etc/fstab # 注释/dev/mapper/centos-swap swap

# 打开kubenetes防火墙端口
# [WARNING Firewalld]: firewalld is active, please ensure ports [6443 10250] are open or your cluster may not function correctly
firewall-cmd --add-port=6443/tcp --permanent
firewall-cmd --add-port=10250/tcp --permanent
firewall-cmd --add-port=8080/tcp --permanent
firewall-cmd --reload

# 安装 Docker 使用的文件驱动是 cgroupfs, 与 kubenetes 的不一致
# [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"]
}
EOF
# 重启Docker
systemctl daemon-reload
systemctl restart docker

# CPU核数不足2
# [ERROR NumCPU]: the number of available CPUs 1 is less than the required 2

# 开启桥接网络支持
# [ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables contents are not set to 1
# [ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1
cat <<EOF >  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF
sysctl -p /etc/sysctl.d/k8s.conf

# 配置相应主机名
vim /etc/hosts # 192.168.31.229 k8s-master
```

#### 2.安装Docker

```shell
# 安装docker的yum源
yum install -y yum-utils
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

# 查看所有Docker版本
yum list docker-ce --showduplicates

# 安装 18.06.3.ce-3.el7 版本
yum install -y docker-ce-18.06.3.ce-3.el7

# 启动 Docker
systemctl start docker

# 设置开机启动
systemctl enable docker
```

#### 3.安装kubelet kubectl kubeadm

```shell
# 安装kubelet的yum源
vim /etc/yum.repos.d/kubernetes.repo
```

```shell
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
```

```shell
# 安装kubelet kubectl kubeadm(安装kubeadm自动安装kubelet kubectl)
yum install -y kubeadm-1.14.1-0

# 设置开机启动
systemctl enable kubelet.service

# 查看kubelet日志
journalctl -xefu kubelet

# 使用国内镜像预先获取
# 查看所需的镜像
kubeadm config images list
# k8s.gcr.io/kube-apiserver:v1.14.1
# k8s.gcr.io/kube-controller-manager:v1.14.1
# k8s.gcr.io/kube-scheduler:v1.14.1
# k8s.gcr.io/kube-proxy:v1.14.1
# k8s.gcr.io/pause:3.1
# k8s.gcr.io/etcd:3.3.10
# k8s.gcr.io/coredns:1.3.1
# 拉取国内镜像
docker pull gcr.azk8s.cn/google-containers/kube-apiserver:v1.14.1
docker pull gcr.azk8s.cn/google-containers/kube-controller-manager:v1.14.1
docker pull gcr.azk8s.cn/google-containers/kube-scheduler:v1.14.1
docker pull gcr.azk8s.cn/google-containers/kube-proxy:v1.14.1
docker pull gcr.azk8s.cn/google-containers/pause:3.1
docker pull gcr.azk8s.cn/google-containers/etcd:3.3.10
docker pull gcr.azk8s.cn/google-containers/coredns:1.3.1
# 修改为官网tag
docker tag cfaa4ad74c37 k8s.gcr.io/kube-apiserver:v1.14.1
docker tag 20a2d7035165 k8s.gcr.io/kube-proxy:v1.14.1
docker tag efb3887b411d k8s.gcr.io/kube-controller-manager:v1.14.1
docker tag 8931473d5bdb k8s.gcr.io/kube-scheduler:v1.14.1
docker tag 20a2d7035165 k8s.gcr.io/kube-proxy:v1.14.1
docker tag da86e6ba6ca1 k8s.gcr.io/pause:3.1
docker tag 2c4adeb21b4f k8s.gcr.io/etcd:3.3.10
docker tag eb516548c180 k8s.gcr.io/coredns:1.3.1
# 删除老tag
docker rmi gcr.azk8s.cn/google-containers/kube-apiserver:v1.14.1
docker rmi gcr.azk8s.cn/google-containers/kube-controller-manager:v1.14.1
docker rmi gcr.azk8s.cn/google-containers/kube-scheduler:v1.14.1
docker rmi gcr.azk8s.cn/google-containers/kube-proxy:v1.14.1
docker rmi gcr.azk8s.cn/google-containers/pause:3.1
docker rmi gcr.azk8s.cn/google-containers/etcd:3.3.10
docker rmi gcr.azk8s.cn/google-containers/coredns:1.3.1
```

#### 4.初始化集群

```shell
# 使用kubeadm初始化集群
kubeadm init --kubernetes-version=v1.14.1 --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.31.229

# 生成了相关配置文件
/var/lib/kubelet/kubeadm-flags.env
/var/lib/kubelet/config.yaml
/etc/kubernetes/

# 配置kubeadm环境变量
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
echo "export KUBECONFIG=/etc/kubernetes/admin.conf" >> ~/.bash_profile
source ~/.bash_profile

# 直接访问ApiServer
curl --cacert /etc/kubernetes/pki/ca.crt --cert /etc/kubernetes/pki/apiserver-kubelet-client.crt --key /etc/kubernetes/pki/apiserver-kubelet-client.key https://192.168.31.229:6443

# 节点加入
kubeadm join 192.168.31.121:6443 --token b1um68.1tfp7h3aj0hp8ffk \
    --discovery-token-ca-cert-hash sha256:4479828a8cbbbaf5fdd69f3c031701f11978c08e989c65393e4c2c60044f9c04

# 重新生成节点加入脚本
kubeadm token create --print-join-command

# 集群初始化若遇到问题,使用命令进行清理
kubeadm reset
ifconfig cni0 down
ip link delete cni0
ifconfig flannel.1 down
ip link delete flannel.1
rm -rf /var/lib/cni/
```

#### 5.安装 flannel pod 网络

```shell
# 安装 flannel pod 网络
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
```

#### 6.安装kubernetes-dashboard

```shell
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml
# 修改 kubernetes-dashboard.yaml 中用户ID
# 使用国内镜像安装无法获取的国外镜像
docker pull gcr.azk8s.cn/google-containers/kubernetes-dashboard-amd64:v1.10.1
docker tag f9aed6605b81 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1
docker rmi gcr.azk8s.cn/google-containers/kubernetes-dashboard-amd64:v1.10.1
# 查看Pod状态
kubectl get pod -A -o wide

kubectl -n kube-system get secret
kubectl -n kube-system describe secret admin-user-token-88dnx

kubectl -n kube-system get pod
kubectl -n kube-system describe pod kubernetes-dashboard-5b55887bbd-czqnr

kubectl get nodes -A -o wide
kubectl describe node k8s-master
```

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kube-system
```

### k8s-node1

#### 1.执行k8s-master的步骤1、2、3

#### 2.加入master节点

```shell
kubeadm join 192.168.31.121:6443 --token b1um68.1tfp7h3aj0hp8ffk \
    --discovery-token-ca-cert-hash sha256:4479828a8cbbbaf5fdd69f3c031701f11978c08e989c65393e4c2c60044f9c04
```